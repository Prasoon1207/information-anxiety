{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import statistics\n",
    "import ast\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(prop_wise_result, path_to_save):\n",
    "    \n",
    "    popularity = []\n",
    "    variety = []\n",
    "    mean_max_uncertainty = []\n",
    "    mean_max_accuracy = []\n",
    "    accuracy_error = []\n",
    "    uncertainty_error = []\n",
    "    \n",
    "    for index in range(len(prop_wise_result)):\n",
    "        \n",
    "        popularity.append(prop_wise_result[index][0])\n",
    "        variety.append(prop_wise_result[index][1])\n",
    "        mean_max_uncertainty.append(prop_wise_result[index][2])\n",
    "        mean_max_accuracy.append(prop_wise_result[index][3])\n",
    "        accuracy_error.append(prop_wise_result[index][4])\n",
    "        uncertainty_error.append(prop_wise_result[index][5])\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    x_pos = np.arange(len(popularity))\n",
    "    \n",
    "    fig, ax = plt.subplots(2, 2, figsize = (20,10))\n",
    "    ax[0, 0].scatter(popularity, mean_max_accuracy, color='blue')\n",
    "    ax[0, 0].set_ylabel('Mean Max Acc. (F1-Score) per question batch-wise')\n",
    "    ax[0, 0].set_xlabel('log popularity')\n",
    "    ax[0, 0].xaxis.grid(True)\n",
    "    \n",
    "    ax[0, 1].scatter(popularity, accuracy_error, color = 'blue')\n",
    "    ax[0, 1].set_ylabel('Stdev Max Acc. (F1-Score) per question batch-wise')\n",
    "    ax[0, 1].set_xlabel('log popularity')\n",
    "    ax[0, 1].xaxis.grid(True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ax[1, 0].scatter(popularity, mean_max_uncertainty, color='blue')\n",
    "    ax[1, 0].set_ylabel('Mean Max Uncertainty per question batch-wise')\n",
    "    ax[1, 0].set_xlabel('log popularity')\n",
    "    ax[1, 0].xaxis.grid(True)\n",
    "\n",
    "    ax[1, 1].scatter(popularity, uncertainty_error, color = 'blue')\n",
    "    ax[1, 1].set_ylabel('Stdev Max Uncertainty per question batch-wise')\n",
    "    ax[1, 1].set_xlabel('log popularity')\n",
    "    ax[1, 1].xaxis.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path_to_save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(li):\n",
    "    # function to convert a string encoded list to a list data-type\n",
    "    return list(map(ast.literal_eval, li))\n",
    "\n",
    "def extract_results(df):    \n",
    "    \n",
    "    f1_score = process(list(df['f1_scores'])) \n",
    "    exact_match_accuracy = process(list(df['em_scores']))\n",
    "    uncertainty = process(list(df['uncertainty_metric']))\n",
    "    \n",
    "    \n",
    "    variation_f1 = list(map(statistics.stdev, f1_score))\n",
    "    \n",
    "    max_accuracy_per_question = [max(f1_score[index]) for index in range(len(f1_score))]\n",
    "    mean_accuracy_per_question = [statistics.mean(f1_score[index]) for index in range(len(f1_score))]\n",
    "    std_accuracy_per_question = [statistics.stdev(f1_score[index]) for index in range(len(f1_score))]\n",
    "    \n",
    "    max_uncertainty_per_question = [max(uncertainty[index]) for index in range(len(uncertainty))]\n",
    "    mean_uncertainty_per_question = [statistics.mean(uncertainty[index]) for index in range(len(uncertainty))]\n",
    "    std_uncertainty_per_question = [statistics.stdev(uncertainty[index]) for index in range(len(uncertainty))]\n",
    "    \n",
    "    variety = statistics.mean(variation_f1)\n",
    "    mean_max_accuracy = statistics.mean(max_accuracy_per_question)\n",
    "    mean_max_uncertainty = statistics.mean(max_uncertainty_per_question)\n",
    "    \n",
    "    accuracy_error = statistics.stdev(max_accuracy_per_question) # can talk about switching to 'mean_accuracy_per_question'\n",
    "    uncertainty_error = statistics.stdev(max_uncertainty_per_question) # can talk about switching to 'mean_uncertainty_per_question'\n",
    "    \n",
    "    \n",
    "    popularity = math.log2(statistics.mean(list(df['pop'])))\n",
    "    \n",
    "    return (popularity, variety, mean_max_uncertainty, mean_max_accuracy, \n",
    "            accuracy_error, uncertainty_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_results = '/home/prasoon/snap/main/information-anxiety/results/variety'\n",
    "current_prop = 'capital'\n",
    "path_to_save = '/home/prasoon/snap/main/information-anxiety/plots/variety'\n",
    "model_name = 'meta-llama-Llama-2-7b-chat-hf'\n",
    "\n",
    "\n",
    "path_to_model = path_to_results + '/' + model_name \n",
    "prop_wise_result = []\n",
    "for batch_file in os.listdir(path_to_model + '/' + current_prop):\n",
    "    batch_wise_result = []\n",
    "    df = pd.read_csv(path_to_model + '/' + current_prop + '/' + batch_file)\n",
    "    \n",
    "    \n",
    "    features = list(df.columns)\n",
    "    data_extracted = extract_results(df)\n",
    "    \n",
    "    for item in data_extracted:\n",
    "        batch_wise_result.append(item)\n",
    "        \n",
    "    prop_wise_result.append(batch_wise_result)\n",
    "path_to_save = 'results/first_exp_diag/' + current_prop + '/'\n",
    "if not os.path.exists(path_to_save):\n",
    "    os.makedirs(path_to_save)\n",
    "# Create a new directory because it does not exist\n",
    "plot(prop_wise_result, path_to_save + model_name + '.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
